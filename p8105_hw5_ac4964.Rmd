---
title: "p8105_hw5_ac4964"
author: "AnMei Chen"
date: "11/15/2021"
output: github_document
---

```{r}
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis" , 
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

For this problem we are intested in data gathered and made publuc by _The Washington Post_ on homicides in 50 large U.S. cities. The code chunk below imports and cleans the data.

victim_age: char because of "Unknown"
str_c (): join multiple strings into a single string — str_c • string

To summarize within cities to obtain the total number of homicides and the number of unsolved homicides : create a new variable "resolution", map Closed without arrest" and "Open/No arrest" with "unsolved" in resolution and "Closed by arrest" with "solved" using case_when()

case_when(): vectorise multiple if_else() statements.

count the city_state and found a data entry issue in TulsaAL, therefore we filter it out.

```{r}
homicide_df = 
  read_csv("./data/homicide-data.csv", na = c("","Unknown")) %>% 
  mutate(
    city_state = str_c(city,state),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved",
      disposition == "Closed by arrest" ~ "solved"
    )
  ) %>% 
  relocate(city_state) %>% 
  filter(city_state != "TulsaAL")
```


prop.test can be used for testing the null that the proportions (probabilities of success) in several groups are the same, or that they equal certain given values.
ex: prop.test(x = 5, n = 10) => 0.5

Let's focus on Baltimore, MD.

```{r}
baltimore_df = 
  homicide_df %>% 
  filter(city_state == "BaltimoreMD")

#resolution == "unsolved" only gives true or false, but summing this up will convert them to 0 or 1 so that we can get the number of unsolved homicides.
# n = total number of homicides in this time period

baltimore_summary = 
  baltimore_df %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  )

baltimore_test =
  prop.test(
    x = baltimore_summary %>% pull(unsolved),
    n = baltimore_summary %>% pull(n)
  )

# use broom::tidy() to organize the output from prop.test into a dataframe so that we can actually use the outputs later.

baltimore_test %>% 
  broom::tidy()
```


Let's try to iterate across cities!
First off, write a function and test it on few sample cities.


```{r}
prop_test_function = function(city_df) {
  
  city_summary = 
    city_df %>% 
    summarize(
      unsolved = sum(resolution == "unsolved"),
      n = n()
    )

  city_test =
    prop.test(
     x = city_summary %>% pull(unsolved),
     n = city_summary %>% pull(n)
    )
  
  return(city_test)
  
}


prop_test_function(baltimore_df)


homicide_df %>% 
  filter(city_state == "AlbuquerqueNM") %>% 
  prop_test_function()
```


Now, lets iterate across all cities.

1. nest uid:resolution and save them into new variable "data"
2. Iteration: map everything in "data" and apply "prop_test_function" across "data", then create a new variable named "test_results"
3. Iteration: map everything in "test_results" and apply "broom::tidy" across "data", then create a new variable named "tidy_results"
4. unest the test_results to get the results

```{r}
results_df = 
  homicide_df %>% 
  nest(data = uid:resolution) %>% 
  mutate(
    test_results = map(data,prop_test_function),
    tidy_results = map(test_results,broom::tidy)
  ) %>% 
  select(city_state,tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))

```


Try to make a plot showing estimates and confidence intervals.

```{r}
results_df %>%
  mutate(
    city_state = fct_reorder(city_state,estimate)
  ) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
  
```


```{r}
homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    unsolved = sum(resolution == "unsolved"),
    n = n()
  ) %>% 
  mutate(
    test_results = map2(unsolved,n,prop.test),
    tidy_results = map(test_results,broom::tidy)
  ) %>% 
  select(city_state,tidy_results) %>% 
  unnest(tidy_results) %>% 
  select(city_state, estimate, starts_with("conf"))
```


## Problem 2

create a dataframe containing all file names

```{r}
file_list_df = 
  tibble(
    files = list.files("./data/zip_data/"))
```

Iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe

```{r}

file_name_function = function(name) {
  
  file_name_df =
    tibble(
      file_name = paste("./data/zip_data/", name, sep = "")
    )
  
  return(file_name_df)
}

new_name = file_name_function(file_list_df[[1]])

file_df = 
  map(new_name, read_csv)
```

Tidy the result; manipulate file names to include control arm and subject ID, make sure weekly observations are “tidy”, and do any other tidying that’s necessary

```{r}
file_list_df = 
  tibble(
    files = list.files("./data/zip_data/"))

new_file_list_df = 
  file_list_df %>% 
  separate(files, into = c("con_or_exp","subject_id"), "_") %>% 
  mutate(
    subject_id = str_replace(subject_id, ".csv","")
  )

tidy_results = 
  cbind(new_file_list_df,file_df) %>% 
  pivot_longer(
    file_name.week_1:file_name.week_8,
    names_prefix = "file_name.week_",
    names_to = "week",
    values_to = "observation"
  ) 
  
```

Make a spaghetti plot showing observations on each subject over time, and comment on differences between groups.

```{r}
tidy_results %>% 
  ggplot(aes(x = as.numeric(week), y = observation, color = subject_id)) +
  geom_line() +
  labs(
    title = "Observations On Each Subject Over Time",
    x = "Week",
    y = "Observations",
  ) +
  facet_grid(. ~ con_or_exp)
```



## Problem 3

The code chunk below loads the iris dataset from the tidyverse package and introduces some missing values in each column. The purpose of this problem is to fill in those missing values.

```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = 
  iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```


```{r}
fill_in_character = 
  iris_with_missing %>% 
  mutate(
    Species = replace_na(Species, "virginica")
  )

fill_in_numbers = 
  iris_with_missing %>% 
  mutate(
    Sepal.Length = replace_na(Sepal.Length, mean(Sepal.Length, na.rm = TRUE))
  )
```

There are two cases to address:
For numeric variables, you should fill in missing values with the mean of non-missing values
For character variables, you should fill in missing values with "virginica"

Write a function that takes a vector as an argument; replaces missing values using the rules defined above; and returns the resulting vector.

```{r}
fill_in_missing = function(vector){
  
  if (is.numeric(vector)) {
    
    vector = replace_na(vector, mean(vector, na.rm = TRUE))
    
  }
  
  if (is.character(vector)) {
    
    vector = replace_na(vector, "virginica")
    
  }
  
  return(vector)
}

```

Apply this function to the columns of iris_with_missing using a map statement.

```{r}
new_iris_with_missing =
  tibble(map_df(iris_with_missing, fill_in_missing))

new_iris_with_missing
```

